{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3ku5HNpXiSK"
   },
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT9S7F4mXiSM"
   },
   "source": [
    "Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h08vTNxRXiSM"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jBcklMgcXiSM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741923214749,
     "user_tz": -480,
     "elapsed": 17543,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "16a3eb9e-ad54-428a-a8e2-6e51c8d07c9c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Collecting xformers==0.0.29\n",
      "  Downloading xformers-0.0.29-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Downloading xformers-0.0.29-cp311-cp311-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m15.3/15.3 MB\u001B[0m \u001B[31m90.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m76.1/76.1 MB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m318.9/318.9 kB\u001B[0m \u001B[31m26.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xformers, trl, bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.3 trl-0.15.2 xformers-0.0.29\n",
      "Collecting cut_cross_entropy\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2025.3.9-py3-none-any.whl.metadata (17 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading unsloth_zoo-2025.3.9-py3-none-any.whl (120 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m120.8/120.8 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: unsloth_zoo, cut_cross_entropy\n",
      "Successfully installed cut_cross_entropy-25.1.1 unsloth_zoo-2025.3.9\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
      "Collecting hf_transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m485.4/485.4 kB\u001B[0m \u001B[31m31.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m3.6/3.6 MB\u001B[0m \u001B[31m74.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m194.8/194.8 kB\u001B[0m \u001B[31m17.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xxhash, hf_transfer, dill, multiprocess, datasets\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.3.9 requires tyro, which is not installed.\n",
      "unsloth-zoo 2025.3.9 requires protobuf<4.0.0, but you have protobuf 4.25.6 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed datasets-3.3.2 dill-0.3.8 hf_transfer-0.1.9 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Collecting protobuf==3.20.3\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m162.1/162.1 kB\u001B[0m \u001B[31m12.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.6\n",
      "    Uninstalling protobuf-4.25.6:\n",
      "      Successfully uninstalled protobuf-4.25.6\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.3.9 requires tyro, which is not installed.\n",
      "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       },
       "id": "59228e82f60b46beacd5fcfd10ac516a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers-cfg\n",
      "  Downloading transformers_cfg-0.2.7-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading transformers_cfg-0.2.7-py3-none-any.whl (67 kB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m67.4/67.4 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: transformers-cfg\n",
      "Successfully installed transformers-cfg-0.2.7\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
    "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece datasets huggingface_hub hf_transfer\n",
    "    !pip install protobuf==3.20.3 # required\n",
    "    !pip install --no-deps transformers-cfg\n",
    "    # !pip install --no-deps unsloth\n",
    "    # !git clone https://github.com/jedt/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7SSPPN8-e-c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741927615480,
     "user_tz": -480,
     "elapsed": 2308,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "d084c8ad-6ac6-47f9-e4ba-75a54dc1cd37"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: xformers==0.0.29 in /usr/local/lib/python3.11/dist-packages (0.0.29)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# pip install \"git+https://github.com/username/repository.git@main#egg=myproject[dev,test]\"\n",
    "# !pip install https://github.com/unslothai/unsloth@main#egg=unsloth[cu121onlytorch251]\n",
    "\n",
    "!pip install \"git+https://github.com/unslothai/unsloth@main#egg=unsloth[cu121onlytorch251]\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4tCUjwJZvTm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741928837399,
     "user_tz": -480,
     "elapsed": 60363,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "0a8146fc-7163-4f8d-984d-a2424c9b26cb"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[33mDEPRECATION: git+https://github.com/unslothai/unsloth@main#egg=unsloth[cu121onlytorch251] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001B[0m\u001B[33m\n",
      "\u001B[0mCollecting unsloth (from unsloth[cu121onlytorch251])\n",
      "  Cloning https://github.com/unslothai/unsloth (to revision main) to /tmp/pip-install-3bo02mts/unsloth_93ec48e4ebeb4f0886bad225423c9dc7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth /tmp/pip-install-3bo02mts/unsloth_93ec48e4ebeb4f0886bad225423c9dc7\n",
      "  Resolved https://github.com/unslothai/unsloth to commit fe04c014c22616cba56c9ddf7782be8ea8ed117e\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl (from unsloth->unsloth[cu121onlytorch251])\n",
      "  Using cached https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (2.2.3)\n",
      "Collecting torch==2.5.1 (from xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251])\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (12.4.127)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251])\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl->unsloth->unsloth[cu121onlytorch251]) (3.0.2)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for unsloth: filename=unsloth-2025.3.10-py3-none-any.whl size=192773 sha256=01eee8910d199a3db10cbfafab3fd48fa8b837e8939426065a04ebd97177f4c3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n95nkm7k/wheels/e5/2d/3a/25a58242037fbb96f0b6680a838e6b6ae844fc5cfb46bcc62f\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth, triton, torch\n",
      "  Attempting uninstall: unsloth\n",
      "    Found existing installation: unsloth 2025.3.10\n",
      "    Uninstalling unsloth-2025.3.10:\n",
      "      Successfully uninstalled unsloth-2025.3.10\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0\n",
      "    Uninstalling torch-2.6.0:\n",
      "      Successfully uninstalled torch-2.6.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.3.9 requires tyro, which is not installed.\n",
      "torchaudio 2.6.0 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.21.0 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n",
      "transformers-cfg 0.2.7 requires protobuf>=4.25.2, but you have protobuf 3.20.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed torch-2.5.1 triton-3.1.0 unsloth-2025.3.10\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --no-deps torchvision==0.20.1\n",
    "!pip install --no-deps torchaudio==2.5.1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udWi7kD9DU0n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741928916118,
     "user_tz": -480,
     "elapsed": 6420,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "d136a091-eb6f-420c-d346-26d57da1eb23"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torchvision==0.20.1\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/7.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[90mâ•º\u001B[0m\u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m4.1/7.2 MB\u001B[0m \u001B[31m119.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m \u001B[32m7.2/7.2 MB\u001B[0m \u001B[31m121.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m \u001B[32m7.2/7.2 MB\u001B[0m \u001B[31m121.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m7.2/7.2 MB\u001B[0m \u001B[31m67.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0\n",
      "    Uninstalling torchvision-0.21.0:\n",
      "      Successfully uninstalled torchvision-0.21.0\n",
      "Successfully installed torchvision-0.20.1\n",
      "Collecting torchaudio==2.5.1\n",
      "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m61.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.6.0\n",
      "    Uninstalling torchaudio-2.6.0:\n",
      "      Successfully uninstalled torchaudio-2.6.0\n",
      "Successfully installed torchaudio-2.5.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers==4.47.1 --ignore-installed"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n5niyJlfZ8eM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741923478191,
     "user_tz": -480,
     "elapsed": 20535,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "e687a264-b9d5-4e31-edec-31449a07c925"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting transformers==4.47.1\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers==4.47.1)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers==4.47.1)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.47.1)\n",
      "  Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting packaging>=20.0 (from transformers==4.47.1)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.47.1)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.47.1)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.47.1)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers==4.47.1)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.47.1)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.47.1)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.47.1)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.47.1)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.47.1)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.47.1)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.3.9 requires tyro, which is not installed.\n",
      "xformers 0.0.29 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
      "transformers-cfg 0.2.7 requires protobuf>=4.25.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "datasets 3.3.2 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.0 which is incompatible.\n",
      "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.3.0 huggingface-hub-0.29.3 idna-3.10 numpy-2.2.3 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.47.1 typing-extensions-4.12.2 urllib3-2.3.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "certifi"
        ]
       },
       "id": "17af7fa274aa4b9ab66bae4f64411949"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "tovni_TktddS"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip uninstall unsloth -y\n",
    "!git clone https://github.com/jedt/unsloth.git"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/content/unsloth\"))\n",
    "!cd /content/unsloth && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_HFQBPSXiSN"
   },
   "source": [
    "### Tool Calling\n",
    "By definition, Tool Calling refers to the capability of models to interact with external tools. As you may already know, LLMs are excellent at generating text in the manner of question-and-answer pairs, chat-like conversation messages, and others. When provided useful context, LLMs are good at responding to prompts that can be used as actionable command parameters that another system would handle. This could be a search engine, calculators, company APIs, spreadsheets, or SQL queries. These systems when interacted with are usually done in a single command line or if more complex a runnable scripting language such as Bash or Python. The painful part is how to sequence these commands and assign the correct parameter names and values. What if we would just prompt the LLM to do these for us? For example. \"Schedule an appointment for Alice with Bob Monday, 10:00am Eastern time\"\n",
    "\n",
    "### Unsloth\n",
    "\n",
    "For this notebook, we'll use a smaller Qwen2.5 model 1.5B. We will guide you on how to prompt a model to respond in JSON format so we can then parse the results and pass those arguments to a Python script. The intuition for using a small model is that we do not want the model to use its pretraining data for the responses when calculating the vector sum. Smaller models have less stored knowledge and it would be possible that our prompt is not on the training data."
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jfx5fOpXiSN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741933976720,
     "user_tz": -480,
     "elapsed": 54238,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "6151e559-2b67-4c23-a450-a759d67eae5b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.10: Fast Qwen2 patching. Transformers: 4.47.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "from unsloth import FastQwen2Model\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "qwen_models = [\n",
    "    \"unsloth/Qwen2.5-Coder-32B-Instruct\",      # Qwen 2.5 Coder 2x faster\n",
    "    \"unsloth/Qwen2.5-Coder-7B\",\n",
    "    \"unsloth/Qwen2.5-14B-Instruct\",            # 14B fits in a 16GB card\n",
    "    \"unsloth/Qwen2.5-7B\",\n",
    "    \"unsloth/Qwen2.5-72B-Instruct\",            # 72B fits in a 48GB card\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastQwen2Model.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-Coder-1.5B-Instruct\",\n",
    "    max_seq_length = None,\n",
    "    dtype = None,\n",
    "    load_in_4bit = False,\n",
    "    fix_tokenizer = False\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tool Definitions\n",
    "This is a list of all the functions that we would provide to the model. The standard format is from OpenAI's [Function Calling Definition](https://platform.openai.com/docs/guides/function-calling?api-mode=chat#defining-functions)\n",
    "It is highly possible that the model trained for tool calling was in the OpenAI standard format.\n",
    "\n",
    "Below is an example of two function definitions. The function definitions of `get_vector_sum` and `get_dot_product` will then be added to the prompt as a context for our prompt:\n",
    "\n",
    "> Find the sum of a = [1, -1, 2] and b = [3, 0, -4].\n",
    "\n",
    "We can just provide the correct one: `get_vector_sum` but to experiment if the model can identify the correct function to call, we will provide both."
   ],
   "metadata": {
    "id": "m64sv66VHfam"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_tool_definition_list():\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_vector_sum\",\n",
    "                \"description\": \"Get the sum of two vectors\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"list\", \"description\": \"First vector\"},\n",
    "                        \"b\": {\"type\": \"list\", \"description\": \"Second vector\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_dot_product\",\n",
    "                \"description\": \"Get the dot product of two vectors\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"list\", \"description\": \"First vector\"},\n",
    "                        \"b\": {\"type\": \"list\", \"description\": \"Second vector\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "\n",
    "    ]"
   ],
   "metadata": {
    "id": "v6MoZMRQa9jI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741933976721,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below is the user prompt declaration"
  },
  {
   "cell_type": "code",
   "source": [
    "user_query = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Find the sum of a = [1, -1, 2] and b = [3, 0, -4].\"\n",
    "}"
   ],
   "metadata": {
    "id": "23p0W2pPdaZY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935731973,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    }
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"https://cdn-lfs.hf.co/datasets/huggingface/documentation-images/48d216f11e3d8fe183d36c84f1380b54dd18608be60224bd3785007be8d567a7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27function-callin.png%3B+filename%3D%22function-callin.png%22%3B&response-content-type=image%2Fpng&Expires=1741999405&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTk5OTQwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy80OGQyMTZmMTFlM2Q4ZmUxODNkMzZjODRmMTM4MGI1NGRkMTg2MDhiZTYwMjI0YmQzNzg1MDA3YmU4ZDU2N2E3P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=mmBIprXrDD88zZYSN8XglAd1wdmb4NZOZrDvXU7BSpzBn1tJE3MiJ42fruvFmB0yQ6dOsAL8wzn3Xf6MZdJCvOwxtkaPUOe5pp%7Ej7mO1E23FIDNEX0NJAM%7ExUTCCoRBYo3ASnlQEe8tOYwbfpES2CJw-xHHnZK7WTsgGqJBtyyQ20fuT7M1ahPmeS8MLjLJlH9BvQeREP%7EkgfkWj6Cw6Zxzd78gBXs-fVlPlFy2cHD6zKkof-p4tCMSvELnXnT89mIXlpUKcN%7EgmoN38yr90fXU4OYpp9mreeSKQyHtA4D4nfqXh5c4B5b%7EIzssOQYltofpApfVYIHPsKKeuK6Jgcw__&Key-Pair-Id=K3RPWS32NSSJCE\">"
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth.models.llama import generate_with_grammar\n",
    "messages = []\n",
    "def get_vector_sum(a: list[float], b: list[float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Performs element-wise addition of two numerical vectors.\n",
    "\n",
    "    Both vectors must be of the same length and contain numerical values.\n",
    "\n",
    "    Args:\n",
    "        a: First vector containing numerical values\n",
    "        b: Second vector containing numerical values\n",
    "\n",
    "    Returns:\n",
    "        Resulting vector where each element is the sum of corresponding elements in a and b\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If vectors have different lengths\n",
    "\n",
    "    Example:\n",
    "        >>> get_vector_sum([1, 2], [3, 4])\n",
    "        [4, 6]\n",
    "    \"\"\"\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "\n",
    "    return [x + y for x, y in zip(a, b)]\n",
    "\n",
    "messages.append(user_query)\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    add_special_tokens=False,\n",
    "    padding=True,\n",
    "    tools=[get_vector_sum],\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "output = generate_with_grammar(\n",
    "    model=model,\n",
    "    input_ids=input_ids\n",
    ")\n",
    "\n",
    "# Slice output to remove the original prompt (keep only new tokens)\n",
    "generated_tokens = output[:, input_ids.shape[1]:]\n",
    "\n",
    "# Decode only the generated tokens (exclude the prompt)\n",
    "decoded_output = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "for i, message in enumerate(decoded_output):\n",
    "    print(f\"{message}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFRTAly3LfFf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935746917,
     "user_tz": -480,
     "elapsed": 12639,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "57e408e7-e104-4448-c8bc-5e98da7e7054"
   },
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"get_vector_sum\",\n",
      "        \"arguments\": {\n",
      "            \"a\": [1, -1, 2],\n",
      "            \"b\": [3, 0, -4]\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From here we can now parse the arguments provided to use by the model"
   ],
   "metadata": {
    "id": "EESZm0wBNqA2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "content = json.loads(decoded_output[0])\n",
    "arguments = content[0]['arguments']\n",
    "vector_a = arguments['a']\n",
    "vector_b = arguments['b']\n",
    "print(f\"args a: {vector_a}, b: {vector_b}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xCxL_SgM4J0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935748915,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "9b644125-128a-4878-fdeb-4c766cfe3c79"
   },
   "execution_count": 87,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "args a: [1, -1, 2], b: [3, 0, -4]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now actually do the compute"
   ],
   "metadata": {
    "id": "hBRMiKiuN-D4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result = get_vector_sum(vector_a, vector_b)\n",
    "print(f\"result: {result}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvA-YnvRN7vJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935749607,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "b8a5a7e6-fd82-4c25-a883-9c0f487ac62b"
   },
   "execution_count": 88,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "result: [4, -1, -2]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_alphanumeric():\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    result = ''.join(random.choice(characters) for _ in range(9))\n",
    "    return result\n",
    "\n",
    "messages = []\n",
    "\n",
    "messages.append(user_query)\n",
    "tool_call_id = generate_alphanumeric()\n",
    "tool_calls = [{\n",
    "            \"id\": tool_call_id,\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_vector_sum\",\n",
    "                \"arguments\": arguments\n",
    "            }\n",
    "        }]\n",
    "\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": tool_calls\n",
    "})\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": \"get_vector_sum\",\n",
    "    \"content\": result\n",
    "})\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"Answer:\\n\"\n",
    "})\n"
   ],
   "metadata": {
    "id": "j6p7fmcHSCll",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935749965,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    }
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tool_prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    continue_final_message=True,\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    ")\n",
    "tool_prompt = tool_prompt.to(model.device)\n",
    "\n",
    "out = model.generate(**tool_prompt, max_new_tokens=128)\n",
    "generated_text = out[0, tool_prompt['input_ids'].shape[1]:]\n",
    "\n",
    "print(tokenizer.decode(generated_text))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIQBOJ4NQFxW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1741935751791,
     "user_tz": -480,
     "elapsed": 1383,
     "user": {
      "displayName": "Jed",
      "userId": "11553494090571428644"
     }
    },
    "outputId": "6e0c143c-6cdd-4c48-c549-1ab432a79743"
   },
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The sum of the vectors a = [1, -1, 2] and b = [3, 0, -4] is [4, -1, -2].<|im_end|>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Z4NQti2FFFqn"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "12cUzlVDyxosNhe_k4J-g3zQtUmvl2_NR",
     "timestamp": 1741936053454
    }
   ],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
